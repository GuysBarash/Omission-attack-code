# -*- coding: utf-8 -*-
"""imdb_attack.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17iVOtggpoPFDSmbdyCqsTpno5tP3ZMFN

# Imports
"""

import sys

IN_COLAB = 'google.colab' in sys.modules

from operator import itemgetter
import numpy as np
import random
import pandas as pd
import matplotlib.pyplot as plt
import warnings
from datetime import datetime
from tqdm import tqdm
import multiprocessing as mp
from tabulate import tabulate

warnings.filterwarnings('ignore')
plt.style.use('ggplot')

if IN_COLAB:
    get_ipython().magic(u'matplotlib inline')
    from IPython.display import display, HTML

import tqdm

import tensorflow as tf

print(f" TF version: {tf.__version__}")

from keras.datasets import imdb
from keras.utils import np_utils, to_categorical
from keras.models import Sequential

from keras.layers import Dense
from keras.layers import Flatten
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from keras.layers.embeddings import Embedding

from keras.preprocessing import sequence

if not IN_COLAB:
    from tensorflow.python.client import device_lib

    print(device_lib.list_local_devices())

"""# Runtime parameters"""

# Data parameters
top_words = 10000
from_index = 0
WORD_PER_SENTENCE = 500

# Model parameters
train_size = 20000
EPOCS = 10
BATCH_SIZE = 1024

# Adversarial point parametes
ADV_LABEL = 1
ADV_CONFIDENCE_INTERVAL = [0.55, 0.65]

# Genetic attack parmeters
BREAK_ON_TRSH = 0.51
generations = 200
offsprings = 400

# Random seed
RANDOM_SEED = None
if RANDOM_SEED is None:
    RANDOM_SEED = np.random.randint(2 ** 31)

np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)
# tf.set_random_seed(RANDOM_SEED)

"""# Data download and setup"""

# On local use this
if not IN_COLAB:
    # save np.load
    np_load_old = np.load

    # modify the default parameters of np.load
    np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True)

    # call load_data with allow_pickle implicitly set to true
    (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)

    # restore np.load for future normal usage
    np.load = np_load_old
else:
    # On Colab use this
    (X_train, y_train), (X_test, y_test) = imdb.load_data(
        num_words=top_words, index_from=from_index)

X_train = X_train[:train_size]
y_train = y_train[:train_size]

X_test = X_test[:train_size]
y_test = y_test[:train_size]

word_index = imdb.get_word_index()
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
review = [reverse_word_index.get(i - 3, "?") for i in X_train[0]]

X_train = sequence.pad_sequences(X_train, maxlen=WORD_PER_SENTENCE)
X_test = sequence.pad_sequences(X_test, maxlen=WORD_PER_SENTENCE)

X_train = pd.DataFrame(X_train)
data_cols = X_train.columns
label_cols = 'Label'

X_train[label_cols] = y_train
X_test = pd.DataFrame(X_test)
X_test[label_cols] = y_test

# Normalize data
# X_test[data_cols] = X_test[data_cols].div(X_test[data_cols].sum(axis=0), axis=1)
# X_train[data_cols] = X_train[data_cols].div(X_train[data_cols].sum(axis=0), axis=1)
print(f"Test samples: {X_test.shape[0]}")
print(f"Train samples: {X_train.shape[0]}")

# Display part of the data (top 10 lines)
if IN_COLAB:
    display(X_train.iloc[:10])
else:
    print(tabulate(X_train.iloc[:10], headers='keys', tablefmt='psql'))

"""# Build model on original data"""

# create the model [ Embedding + Conv ]
clf = Sequential()
clf.add(Embedding(top_words, 4, input_length=WORD_PER_SENTENCE))
clf.add(Conv1D(filters=4, kernel_size=3, padding='same', activation='relu'))
clf.add(MaxPooling1D(pool_size=2))
clf.add(Flatten())
clf.add(Dense(4, activation='relu'))
clf.add(Dense(1, activation='sigmoid'))
clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(clf.summary())
clf.save_weights('original_w.h5')

# Fit the model
start_time = datetime.now()
clf.fit(X_train[data_cols], X_train[label_cols], validation_data=(X_test[data_cols], X_test[label_cols]), epochs=EPOCS,
        batch_size=BATCH_SIZE, verbose=2)
# Final evaluation of the model
scores = clf.evaluate(X_test[data_cols], X_test[label_cols], verbose=0)
print("Accuracy: %.2f%%" % (scores[1] * 100))
print(f"Duration: {datetime.now() - start_time}")

"""# Choose adversarial datapoint"""

# Find an adverserial example to attack
attack_label = 1
res = clf.predict_proba(X_test[data_cols])
res = pd.DataFrame(res, index=X_test.index)
res['Prediction'] = clf.predict(X_test[data_cols])
res[label_cols] = X_test[label_cols]
res = res[res[label_cols] == attack_label]
res = res[(res['Prediction'] > ADV_CONFIDENCE_INTERVAL[0]) & (res['Prediction'] < ADV_CONFIDENCE_INTERVAL[1])]
adv_idx = res.sample(1).index[0]
adv = pd.DataFrame(columns=X_test.columns)
adv.loc[0] = X_test.loc[adv_idx]

if IN_COLAB:
    display(adv)
else:
    print(tabulate(adv, headers='keys', tablefmt='psql'))

print(f"Original prediction: {adv.loc[0,label_cols]}")
start_prob_of_1 = clf.predict(adv[data_cols])[0, 0]
start_prob_of_0 = 1 - start_prob_of_1
print(f"Range of target: [{ADV_CONFIDENCE_INTERVAL[0]},\t{ADV_CONFIDENCE_INTERVAL[1]}]")
print(f"Classification: {np.round(start_prob_of_1)} prob: {start_prob_of_1:>.3f}")

"""# Attack model"""

# Attack params
df = X_train
budget = 2 * int(np.ceil(np.sqrt(df.shape[0])))
mutation_rate = 5 * 1.0 / budget
parents = 3

per_round_winner = pd.DataFrame(
    columns=['Gen', 'creature_idx', 'prob_of_origin',
             'prob_of_target', 'change'] + [
                's_{}'.format(tk) for tk in range(budget)])
result_summary = pd.DataFrame(columns=['Gen', 'Best score'])
results_memory = pd.DataFrame(columns=['parent_idx', 'prob_of_origin', 'prob_of_target'])


def run_creature(p):
    xdf = df.copy()
    # print(f"Before drop {xdf.shape}")
    xdf = xdf.drop(p, axis=0)
    # print(f"After drop {xdf.shape}")
    clf.load_weights('original_w.h5')
    # tf.set_random_seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)
    random.seed(RANDOM_SEED)

    clf.fit(xdf[data_cols], xdf[label_cols], epochs=EPOCS, batch_size=BATCH_SIZE, verbose=0)
    # scores = clf.evaluate(X_test[data_cols], X_test[label_cols], verbose=0)
    # print("Accuracy: %.2f%%" % (scores[1]*100))
    # print(f"Original prediction: {adv.loc[0,label_cols]}")
    prob = clf.predict(adv[data_cols])[0, 0]
    # print(f"Classification: {np.round(prob)} prob: {prob:>.3f}")
    return prob, clf


def mate(lp):
    # Pick genes
    genepool = set()
    for p in lp:
        genepool = genepool.union(p)
    child = np.random.choice(list(genepool), budget, replace=False)

    # Mutate
    items_to_mutate = sum(
        [np.random.choice([True, False], p=[mutation_rate, 1 - mutation_rate]) for _ in range(budget)])
    gene_options = df.index
    gene_options = np.setdiff1d(gene_options, child)

    items_to_remove = np.random.choice(list(child), items_to_mutate)
    child = np.setdiff1d(child, items_to_remove)

    items_to_add = np.random.choice(gene_options, items_to_mutate)
    child = set(child).union(items_to_add)

    return child


# Choose initial parents
adv_point = adv.loc[0, data_cols]
k_dist = lambda p: ((p - adv_point) ** 2).sum()

creatures_dict = dict()

tparent = df.copy(deep=True)
tparent = tparent[tparent[label_cols] == 1.0]
tparent = tparent[data_cols]
tparent['k_dist'] = tparent.apply(k_dist, axis=1)
tparent = tparent.sort_values(by=['k_dist'], ascending=True)
tparent = tparent.iloc[0:parents * budget]
tparent = tparent.drop(columns=['k_dist'])
tparent = tparent.sort_index()

tparents_idxs = tparent.index
gendf = pd.DataFrame(columns=['parent_idx', 'prob_of_1', 'prob_of_0'], index=range(parents))
for cparent in range(parents):
    p = set(tparents_idxs[budget * cparent:budget * (cparent + 1)])
    hash_p = hash(str(p))
    prob_of_1, _ = run_creature(p)
    gendf.iloc[cparent] = [hash_p, prob_of_1, 1 - prob_of_1]
    creatures_dict[hash_p] = (p, prob_of_1)

if IN_COLAB:
    display(gendf)
else:
    print(tabulate(gendf, headers='keys', tablefmt='psql'))

# Checker
zero_p = set()
checker_repeats = 3
for checker_repeat in range(checker_repeats):
    score_1, clf = run_creature(zero_p)
    print(f"Check {checker_repeat}\t{score_1}")

num_of_creatures = offsprings + parents
xtnd_gendf = pd.DataFrame(columns=['parent_idx', 'prob_of_1', 'prob_of_0'], index=range(num_of_creatures))
xtnd_gendf.iloc[0:parents] = gendf
res_across_gens = list()

for gen_idx in range(generations):
    hash_lp = xtnd_gendf['parent_idx'].iloc[0:parents].values
    lp = [creatures_dict[hash_tp][0] for hash_tp in hash_lp]

    # Run parents
    break_flag = False
    final_winner_idx = -1

    if IN_COLAB:
        loading_bar = tqdm.tqdm_notebook(enumerate(lp), desc=f' eval parents {gen_idx + 1} / {generations}')
    else:
        loading_bar = tqdm.tqdm(enumerate(lp), desc=f' eval parents {gen_idx + 1} / {generations}')

    for pidx, p in loading_bar:
        res = list()
        prob_of_1_1, _ = run_creature(p)
        prob_of_1_2, _ = run_creature(p)
        prob_of_1_3, _ = run_creature(p)
        prob_of_0_1 = 1 - prob_of_1_1
        prob_of_0_2 = 1 - prob_of_1_2
        prob_of_0_3 = 1 - prob_of_1_3

        res += [prob_of_0_1, prob_of_0_2, prob_of_0_3]
        prob_of_0 = np.mean(res)
        prob_of_1 = 1 - prob_of_0
        if (prob_of_0_1 > BREAK_ON_TRSH) and (prob_of_0_2 > BREAK_ON_TRSH) and (prob_of_0_3 > BREAK_ON_TRSH):
            print("We have a winner, breaking.")
            break_flag = True
            final_winner_idx = pidx
        if pidx == 0:
            res_across_gens += [prob_of_0]

        print(f"parent {pidx+1} score: {prob_of_0}. {res}")
        hash_p = hash(str(p))
        creatures_dict[hash_p] = (p, prob_of_1)
        xtnd_gendf.iloc[pidx] = [hash_p, prob_of_1, prob_of_0]

    print(f"original prob of target: {start_prob_of_0}")
    print(f"{pd.Series([start_prob_of_0] + res_across_gens)}")
    plt.plot([start_prob_of_0] + res_across_gens)
    plt.show()
    plt.close('all')
    if break_flag:
        break

    # Run creatures
    if IN_COLAB:
        loading_bar = tqdm.tqdm_notebook(range(offsprings), desc=f' Gen {gen_idx + 1} / {generations}')
    else:
        loading_bar = tqdm.tqdm(range(offsprings), desc=f' Gen {gen_idx + 1} / {generations}')

    for cidx in loading_bar:
        creature_idx = cidx + parents
        cp = mate(lp)
        cp_hash = hash(str(cp))

        prob_of_1, clf = run_creature(cp)
        xtnd_gendf.iloc[creature_idx] = [cp_hash, prob_of_1, 1 - prob_of_1]
        creatures_dict[cp_hash] = (p, prob_of_1)
        # print(f"Hash: {cp_hash} Child {cidx} Score: {1 - prob_of_1}")

    xtnd_gendf = xtnd_gendf.sort_values(by=['prob_of_0'], ascending=False)
    gendf = xtnd_gendf
    print(f"Gen {gen_idx + 1}")

    if IN_COLAB:
        display(gendf)
    else:
        print(tabulate(gendf, headers='keys', tablefmt='psql'))
        pass

"""# Display results"""

# Analyze winner
winner = xtnd_gendf.iloc[final_winner_idx]
winner_hash = winner['parent_idx']
winner_p = creatures_dict[winner_hash][0]

winner_prob_1, winner_clf = run_creature(winner_p)
winner_prob_0 = 1 - winner_prob_1

# xdf = df.copy()
# xdf = xdf.drop(winner_p,axis=0)
# clf.load_weights('original_w.h5')
# clf.fit(xdf[data_cols], xdf[label_cols],epochs=EPOCS, batch_size=256, verbose=0)
# scores = clf.evaluate(X_test[data_cols], X_test[label_cols], verbose=0)
# prob = clf.predict(adv[data_cols])[0,0]
print("")
print(f"Random seed: {RANDOM_SEED}")
print("Accuracy: %.2f%%" % (scores[1] * 100))
print(f"generations completed: {gen_idx + 1}")
print(f"Original prob: {start_prob_of_1}")
print(f"Current prediction: {winner_prob_1}")

print("Data should be storred to:")
print(r'https://docs.google.com/spreadsheets/d/1kb2RJUkMvMAmWOVmHVgIa42tYIOSGZ0NWqplVnv3HRc/edit?usp=sharing')
print(f"{start_prob_of_1}, {winner_prob_1}, {gen_idx + 1}, {RANDOM_SEED}")
