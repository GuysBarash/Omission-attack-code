# -*- coding: utf-8 -*-
"""pytorch_knn_attack.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rRlyAFROAQ09X3unEKRcHo5RYx2ap_5o
"""

import os
import re
import shutil
import time
import json
from matplotlib import pyplot
from matplotlib.image import imread

import pandas as pd
import numpy as np
import sklearn

import torchvision
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import torch.optim as optim
import torchvision.datasets as datasets
from torch.autograd import Variable
from torchsummary import summary
from PIL import Image
import PIL
from IPython.display import display, HTML

from tqdm import tqdm
from datetime import datetime
import sys


def experiment_instance(randomseed=0):
    import sys

    IN_COLAB = 'google.colab' in sys.modules
    if IN_COLAB:
        from google.colab import drive

        drive.mount('/content/drive')
        selected_random_seed = 74  # np.random.randint(2**32 - 2)
    else:
        selected_random_seed = randomseed

    torch.manual_seed(selected_random_seed)
    np.random.seed(selected_random_seed)
    print(f"Selected random seed: {selected_random_seed}")

    def clear_folder(path, clear_if_exist=False):
        if os.path.exists(path) and clear_if_exist:
            all_items_to_remove = [os.path.join(path, f) for f in os.listdir(path)]
            for item_to_remove in all_items_to_remove:
                if os.path.exists(item_to_remove) and not os.path.isdir(item_to_remove):
                    os.remove(item_to_remove)
                else:
                    shutil.rmtree(item_to_remove)

        if not os.path.exists(path):
            os.makedirs(path)

    def accuracy(outputs, labels):
        _, preds = torch.max(outputs, dim=1)
        t0 = preds.int() == labels.int()
        t1 = torch.sum(t0)
        t1 = t1.item()
        t2 = len(preds)
        t3 = t1 / t2
        t3 = torch.tensor(t3)
        return t3

    class KNNDetector:
        def __init__(self, transform):
            # Load the pretrained model
            self.model = models.resnet152(pretrained=True)
            self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
            self.model = self.model.to(self.device)

            self.transform = transform
            self.layer = None

        def reset(self, use_cude=False):
            self.model = models.resnet152(pretrained=True)
            if use_cude:
                self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
                self.model = self.model.to(self.device)

        def get_vector(self, image_path):
            # 1. Load the image with Pillow library
            img = Image.open(image_path)

            # 2. Create a PyTorch Variable with the transformed image
            img_t = self.transform(img)
            batch_t = torch.unsqueeze(img_t, 0)
            batch_t = batch_t.to(self.device)

            my_embedding = torch.zeros([batch_t.shape[0], 2048, batch_t.shape[0], batch_t.shape[0]])

            def copy_data(m, i, o):
                my_embedding.copy_(o.data)

            # 5. Attach that function to our selected layer
            h = self.layer.register_forward_hook(copy_data)

            # Predict
            self.model.eval()
            out = self.model(batch_t)

            # outvec = torch.nn.functional.softmax(out[0], dim=0)
            # leading_idx = list(zip(outvec.sort()[1][-10:], outvec.sort()[0][-10:]))
            # leading_labels = [idx2label(int(idx[0])) for idx in leading_idx]
            # leading_p = [100 * float(idx[1]) for idx in leading_idx]
            # pred = pd.Series(index=leading_labels, data=leading_p)

            h.remove()
            embd = my_embedding[0, :, 0, 0]

            return embd.clone()

        def get_vectors(self, paths, batch_size=20):
            # 1. Load the image with Pillow library
            imgs = [Image.open(image_path) for image_path in paths]
            # 2. Create a PyTorch Variable with the transformed image
            imgs_t = [self.transform(img) for img in imgs]
            ret = None
            for batch_idx, batch_start_idx in enumerate(np.arange(0, len(imgs_t), batch_size)):
                batch_end_idx = batch_start_idx + batch_size
                sub_img_t = imgs_t[batch_start_idx:batch_end_idx]
                tensor_t = torch.stack(sub_img_t)
                tensor_t = tensor_t.to(self.device)

                my_embedding = torch.zeros(
                    [tensor_t.shape[0], 2048, 1, 1])

                def copy_data(m, i, o):
                    my_embedding.copy_(o.data)

                # 5. Attach that function to our selected layer
                h = self.layer.register_forward_hook(copy_data)

                # Predict
                self.model.eval()
                out = self.model(tensor_t)

                h.remove()
                embd = my_embedding[:, :, 0, 0]

                if ret is None:
                    ret = embd.clone()
                else:
                    ret = torch.cat([ret.clone(), embd.clone()], 0)
            return ret

        def get_similarities(self, src_path, imgs):
            self.layer = self.model._modules['avgpool']

            src_vec = self.get_vector(src_path)
            trgt_vectors = self.get_vectors(imgs)
            cos = nn.CosineSimilarity(dim=1, eps=1e-6)
            similarities = cos(src_vec.unsqueeze(0), trgt_vectors)
            return similarities

    class Learner:
        def __init__(self, transform, model_type='alexnet'):
            self.transform = transform
            self.model = None
            self.model_type = model_type
            self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

        def reset(self, seed=0, ):
            torch.cuda.empty_cache()
            torch.manual_seed(seed)
            np.random.seed(seed)
            num_classes = 2
            print(f"[Training using: {self.model_type}]")

            if self.model_type == 'resnet18':
                self.model = models.resnet18(pretrained=True)
                for param in self.model.parameters():
                    param.requires_grad = False
                num_ftrs = self.model.fc.in_features
                self.model.fc = nn.Linear(num_ftrs, num_classes)
            elif self.model_type == 'alexnet':
                self.model = models.alexnet(pretrained=True)
                for param in self.model.parameters():
                    param.requires_grad = False
                num_ftrs = self.model.classifier[6].in_features
                self.model.classifier[6] = nn.Linear(num_ftrs, num_classes)
            elif self.model_type == 'vgg11':
                self.model = models.vgg11_bn(pretrained=True)
                for param in self.model.parameters():
                    param.requires_grad = False
                num_ftrs = self.model.classifier[6].in_features
                self.model.classifier[6] = nn.Linear(num_ftrs, num_classes)

            else:
                print("ERROR IN MODEL SELECTION")

            self.model = self.model.to(self.device)
            self.criterion = nn.CrossEntropyLoss()
            self.optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)

        def train(self, traindata, vlddata=None, advdata=None, epochs=1, randomSeed=0,
                  batch_size=512,
                  ):
            self.reset(seed=randomSeed)

            if type(traindata) is str:
                traindata = torchvision.datasets.ImageFolder(traindata, transform=self.transform)

            if type(vlddata) is str:
                vlddata = torchvision.datasets.ImageFolder(vlddata, transform=self.transform)

            train_time_start = datetime.now()
            print(f"[Train size: {len(traindata)}][Batch size: {batch_size}]")
            for epoch in range(epochs):
                epoch_time_start = datetime.now()
                samples = list()
                labels = list()
                for i, data in enumerate(traindata, 0):
                    c_inputs, c_label = data
                    samples.append(c_inputs)
                    labels.append(c_label)

                c = list(zip(samples, labels))
                np.random.shuffle(c)
                samples, labels = zip(*c)
                train_loss = 0
                train_acc = 0
                # samples = samples[:10] # DEBUG LINE
                for batch_idx, batch_start_idx in enumerate(np.arange(0, len(samples), batch_size)):
                    batch_samples = samples[batch_start_idx:batch_start_idx + batch_size]
                    batch_labels = labels[batch_start_idx:batch_start_idx + batch_size]
                    batch_samples = torch.stack(batch_samples)
                    batch_labels = torch.Tensor(batch_labels)
                    batch_samples = batch_samples.to(self.device)
                    batch_labels = batch_labels.to(self.device)

                    self.optimizer.zero_grad()

                    outputs = self.model(batch_samples)
                    train_accuracy = accuracy(outputs, batch_labels)
                    loss = self.criterion(outputs, batch_labels.long())
                    loss.backward()
                    self.optimizer.step()

                    train_acc += float(train_accuracy)
                    train_loss += float(loss)
                train_acc /= (batch_idx + 1)

                vld_acc = -1
                vld_loss = -1
                if vlddata is not None:
                    samples = list()
                    labels = list()
                    for i, data in enumerate(vlddata, 0):
                        c_inputs, c_label = data
                        samples.append(c_inputs)
                        labels.append(c_label)

                    c = list(zip(samples, labels))
                    np.random.shuffle(c)
                    samples, labels = zip(*c)
                    vld_acc = 0.0
                    vld_loss = 0.0
                    # samples = samples[:10] # DEBUG LINE
                    for batch_idx, batch_start_idx in enumerate(np.arange(0, len(samples), batch_size)):
                        batch_samples = samples[batch_start_idx:batch_start_idx + batch_size]
                        batch_labels = labels[batch_start_idx:batch_start_idx + batch_size]
                        batch_samples = torch.stack(batch_samples)
                        batch_labels = torch.Tensor(batch_labels)
                        batch_samples = batch_samples.to(self.device)
                        batch_labels = batch_labels.to(self.device)

                        outputs = self.model(batch_samples)
                        vld_accuracy = accuracy(outputs, batch_labels)
                        loss = self.criterion(outputs, batch_labels.long())
                        vld_acc += float(vld_accuracy)
                        vld_loss += float(loss)
                    vld_acc /= batch_idx + 1

                now_time = datetime.now()
                msg = ''
                msg += f'[train time: {now_time - train_time_start}]'
                msg += f'[epoch time: {now_time - epoch_time_start}]'
                msg += '\t'
                msg += f'[Epoch {epoch:>3}/{epochs:>3}]'
                msg += '\t'
                msg += f'[Train acc {train_acc:>.4f}]'
                msg += f'[Train loss {train_loss:>.4f}]'
                msg += '\t'
                msg += f'[vld acc {vld_acc:>.4f}]'
                msg += f'[vld loss {vld_loss:>.4f}]'

                src_prob, trgt_prob = 1.0, -1.0
                if advdata is not None:
                    src_prob, trgt_prob = self.predict_advesary(advdata)
                    msg += '\t'
                    # msg += f'[SRC: {src_prob:>.3f}][Trgt: {trgt_prob:>.3f}]'
                    if src_prob > trgt_prob:
                        msg += f'[<< SRC: {src_prob:>+.3f} >>][   Trgt: {trgt_prob:>+.3f}   ]'
                    else:
                        msg += f'[   SRC: {src_prob:>+.3f}   ][<< Trgt: {trgt_prob:>+.3f} >>]'

                print(msg)

            torch.cuda.empty_cache()
            return src_prob, trgt_prob, vld_acc

        def get_predictions(self, data_to_predict):
            if type(data_to_predict) is str:
                data_to_predict = torchvision.datasets.ImageFolder(data_to_predict, transform=self.transform)

            for i, data in enumerate(data_to_predict, 0):
                inputs, labels = data
                inputs = inputs.to(self.device)
                labels = labels.to(self.device)

                outputs = self.model(inputs)
            return outputs

        def predict_advesary(self, advdata):
            if type(advdata) is str:
                advdata = torchvision.datasets.ImageFolder(advdata, transform=self.transform)

            samples = list()
            labels = list()
            for i, data in enumerate(advdata, 0):
                c_inputs, c_label = data
                samples.append(c_inputs)
                labels.append(c_label)

            c = list(zip(samples, labels))
            np.random.shuffle(c)
            samples, labels = zip(*c)
            samples = torch.stack(samples)
            labels = torch.Tensor(labels)
            samples = samples.to(self.device)
            labels = labels.to(self.device)
            outputs = self.model(samples)

            src_label = int(labels[0])
            trgt_label = 1 - src_label

            src_prob = float(outputs.squeeze(0)[src_label])
            trgt_prob = float(outputs.squeeze(0)[trgt_label])

            return src_prob, trgt_prob

    class DataOmittor:
        def __init__(self, workdir, dataset_source_dir, ommited_dir, transform):
            self.workdir = workdir
            self.transform = transform

            self.train_source_dir = dataset_source_dir

            self.adv_source_dir = os.path.join(self.workdir, 'adv')
            self.adv_idx = -1
            self.adv = None

            self.attacked_train_dir = os.path.join(self.workdir, 'train_current')
            self.train_idxs = -1
            self.attacked_train = None

            self.ommited_dir = ommited_dir
            self.omitted_train = None
            self.ommited_idxs = list()

            clear_folder(self.attacked_train_dir, clear_if_exist=True)
            clear_folder(self.adv_source_dir, clear_if_exist=True)
            clear_folder(self.ommited_dir, clear_if_exist=True)

            self.uid = 0

            self.main_dataset = torchvision.datasets.ImageFolder(self.train_source_dir, transform=transform)
            self.main_map = self.map_dataset(self.train_source_dir)

        def map_dataset(self, dataset_path):
            classes = os.listdir(dataset_path)
            imgs = list()
            imgs_path = list()
            labels = list()
            for t_class in classes:
                src_class_dir = os.path.join(dataset_path, t_class)
                c_imgs = os.listdir(src_class_dir)
                c_imgs_path = [os.path.join(src_class_dir, img) for img in c_imgs]
                c_labels = [t_class] * len(c_imgs_path)

                imgs += c_imgs
                imgs_path += c_imgs_path
                labels += c_labels

            mapdf = pd.DataFrame(columns=['idx', 'img', 'label', 'class', 'path'], index=range(len(imgs)))
            mapdf['idx'] = range(len(imgs))
            mapdf['img'] = imgs
            mapdf['label'] = labels
            mapdf['class'] = mapdf['label'].map(self.main_dataset.class_to_idx)
            mapdf['path'] = imgs_path

            return mapdf

        def make_from_list(self, l):
            j = 3

        def get_map(self, uid=-1):
            if uid < 0:
                return self.main_map
            else:
                return None

        # Adv handling
        def get_adv_idx(self):
            return self.adv_idx

        def get_adv_path(self, exact=False):
            if not exact:
                return self.adv_source_dir
            else:
                return self.adv['new path']

        def get_adv(self):
            return self.adv

        def make_adv(self, idx):
            self.adv_idx = idx
            adv_row = self.main_map.loc[idx]

            clear_folder(self.adv_source_dir, clear_if_exist=True)
            for c_class in self.main_dataset.classes:
                ppath = os.path.join(self.adv_source_dir, c_class)
                clear_folder(ppath, clear_if_exist=True)

            src_path = adv_row['path']
            trgt_path = os.path.join(self.adv_source_dir, adv_row['label'], adv_row['img'])
            shutil.copy(src_path, trgt_path)

            self.adv = pd.Series(index=adv_row.index, data=adv_row.values)
            self.adv['new path'] = trgt_path

        def get_adv_class(self):
            return self.adv['class']

        # Attacked Dataset handling

        def make_train_set(self, train_idx):
            self.train_idxs = train_idx

            self.attacked_train = self.main_map.loc[self.train_idxs].copy()
            self.omitted_train = self.main_map.loc[
                ~self.main_map.index.isin(np.concatenate(([self.adv_idx], self.train_idxs)))]
            self.ommited_idxs = self.omitted_train.idx.values
            self.attacked_train['new path'] = 'X'

            clear_folder(self.attacked_train_dir, clear_if_exist=True)
            for c_class in self.main_dataset.classes:
                ppath = os.path.join(self.attacked_train_dir, c_class)
                clear_folder(ppath, clear_if_exist=True)

            clear_folder(self.ommited_dir, clear_if_exist=True)
            for c_class in self.main_dataset.classes:
                ppath = os.path.join(self.ommited_dir, c_class)
                clear_folder(ppath, clear_if_exist=True)

            def _move_sample(src, trgt):
                shutil.copy(src, trgt)
                return trgt

            for _, src in self.attacked_train.iterrows():
                src_path = src['path']
                trgt_path = os.path.join(self.attacked_train_dir, src['label'], src['img'])
                self.attacked_train.loc[src['idx'], 'new path'] = _move_sample(src_path, trgt_path)

            for _, src in self.omitted_train.iterrows():
                src_path = src['path']
                trgt_path = os.path.join(self.ommited_dir, src['label'], src['img'])
                self.omitted_train.loc[src['idx'], 'new path'] = _move_sample(src_path, trgt_path)

        def get_train_path(self):
            return self.attacked_train_dir

        def get_train(self):
            self.attacked_train

        def get_attack_train_idx(self):
            return self.train_idxs

        def get_train_size(self):
            return self.train_idxs.shape[0]

        # Original dataset
        def get_origina_train_set_path(self):
            return self.train_source_dir

    img_shape = (256, 256)
    transform = transforms.Compose([
        transforms.Resize(img_shape),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
    ])

    # Define paths
    import sys

    IN_COLAB = 'google.colab' in sys.modules
    if IN_COLAB:
        work_dir = '/content/drive/MyDrive/Kaggle'
    else:
        work_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

    # data_dir = os.path.join(work_dir, 'dogs_n_cats')
    print(f"File --> {__file__} --> {os.path.dirname(__file__)}")
    data_dir = os.path.join(work_dir, 'frogs_n_planes')
    train_dir = os.path.join(data_dir, 'train')
    omitted_dir = os.path.join(data_dir, 'omitted')
    test_dir = os.path.join(data_dir, 'test')
    adv_dir = os.path.join(data_dir, 'adv')

    clear_folder(work_dir)
    clear_folder(data_dir)
    clear_folder(train_dir)
    clear_folder(test_dir)
    clear_folder(adv_dir)
    clear_folder(omitted_dir)

    """Start"""

    omittor = DataOmittor(data_dir, train_dir, ommited_dir=omitted_dir, transform=transform)
    mapdf = omittor.get_map()

    """Choose adversarial sample randomly"""

    adv_idx = mapdf['idx'].sample(1).iloc[0]
    train_idx = mapdf.loc[~mapdf['idx'].eq(adv_idx), 'idx'].values
    print(f"Adversarial sample: {adv_idx}")

    """Make train set, no attack yet"""

    omittor.make_adv(idx=adv_idx)
    omittor.make_train_set(train_idx=train_idx)
    print(f"Number of samples for training: {omittor.get_train_size()}")

    img = Image.open(omittor.get_adv_path(exact=True))
    img_size = 224, 224
    img = img.resize(img_size, Image.ANTIALIAS)
    display(img)

    """Results before omission"""

    learner = Learner(transform)
    src_prob_before, trgt_prob_before, vld_acc_before = learner.train(omittor.get_train_path(), vlddata=test_dir,
                                                                      advdata=omittor.get_adv_path(), epochs=40)

    adv_hit_before = src_prob_before - trgt_prob_before

    """Omission"""

    knn_detector = KNNDetector(transform)
    knndf = omittor.attacked_train.copy()
    simis = knn_detector.get_similarities(src_path=omittor.get_adv_path(exact=True),
                                          imgs=omittor.attacked_train['path'])
    knndf['similarities'] = simis
    knndf = knndf.sort_values(by=['similarities'], ascending=False)
    budget = int(np.ceil(np.sqrt(knndf.shape[0])))
    idx_to_remove_df = knndf.loc[knndf['class'] == omittor.get_adv_class()].iloc[:budget]
    idx_to_remove = idx_to_remove_df['idx']
    idx_to_keep = knndf.loc[~knndf.index.isin(idx_to_remove), 'idx'].values

    print(f"Removing: [Shape: {idx_to_remove_df.shape[0]}]")
    display(HTML(idx_to_remove_df.to_html()))

    omittor.make_adv(idx=adv_idx)
    omittor.make_train_set(train_idx=idx_to_keep)
    print(f"Number of samples for training: {omittor.get_train_size()}")

    """Results after omission"""

    if adv_hit_before < 0:
        adv_hit_after = 0.0
        vld_acc_after = 0.0
    else:
        learner = Learner(transform)
        src_prob_after, trgt_prob_after, vld_acc_after = learner.train(omittor.get_train_path(), vlddata=test_dir,
                                                                       advdata=omittor.get_adv_path(), epochs=40)
        adv_hit_after = src_prob_after - trgt_prob_after

    msg = ''
    msg += f'Random seed: {selected_random_seed}' + '\n'
    msg += f"Adversarial sample: {adv_idx}" + '\n'
    msg += f'Prediction before: {adv_hit_before:>+.3f}' + '\n'
    msg += f'Prediction after: {adv_hit_after:>+.3f}' + '\n'
    msg += f'Acc drop: {vld_acc_before - vld_acc_after:>+.3f}' + '\n'
    symbol = 'MISSINGSYMBOL'
    if (adv_hit_before > 0) and (adv_hit_after < 0):
        msg += 'RES: WIN'
        symbol = 'V'
    elif (adv_hit_before > 0) and (adv_hit_after > 0):
        msg += 'RES: LOSE'
        symbol = 'X'
    else:
        msg += 'RES: CANCELLED EXP'
        symbol = 'O'
    msg += '\n@'

    report_path = os.path.join(work_dir, f'Report_{symbol}_{selected_random_seed}.txt')
    with open(report_path, 'w+') as ffile:
        ffile.write(msg)

    print(msg)


if __name__ == '__main__':
    steps = 1000
    start_seed = 100
    for exp in range(start_seed, start_seed + steps):
        experiment_instance(randomseed=exp)
