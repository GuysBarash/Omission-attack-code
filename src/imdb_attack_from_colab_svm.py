# -*- coding: utf-8 -*-
"""imdb_attack_svm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kUP5-QrflD1ihlfn2Nkg_RGZHKBh-2hM

Doing the Imports
"""

colab_mode = False
svm_mode = True

import os
from operator import itemgetter
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
from datetime import datetime
from tqdm import tqdm
import multiprocessing as mp
from tabulate import tabulate

warnings.filterwarnings('ignore')
plt.style.use('ggplot')

if colab_mode:
    get_ipython().magic(u'matplotlib inline')
    from IPython.display import display, HTML

import tqdm

import tensorflow as tf
from keras.datasets import imdb
from keras.utils import np_utils, to_categorical
from keras.models import Sequential

from keras.layers import Dense
from keras.layers import Flatten
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from keras.layers.embeddings import Embedding

from keras.preprocessing import sequence

from sklearn import svm
import sklearn
from sklearn.neighbors import KNeighborsClassifier as KNN

top_words = 50
from_index = 0
number_of_documents = 2000

# On local use this
local_mode = True
if local_mode:
    # save np.load
    np_load_old = np.load

    # modify the default parameters of np.load
    np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)

    # call load_data with allow_pickle implicitly set to true
    (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)
    X_train = X_train[:number_of_documents]
    y_train = y_train[:number_of_documents]
    X_test = X_test[:number_of_documents]
    y_test = y_test[:number_of_documents]

    # restore np.load for future normal usage
    np.load = np_load_old
else:
    # On Colab use this
    (X_train, y_train), (X_test, y_test) = imdb.load_data(
        num_words=top_words, index_from=from_index)

word_index = imdb.get_word_index()
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
review = [reverse_word_index.get(i - 3, "?") for i in X_train[0]]

max_words = 500
X_train = sequence.pad_sequences(X_train, maxlen=max_words)
X_test = sequence.pad_sequences(X_test, maxlen=max_words)

X_train = pd.DataFrame(X_train)
data_cols = X_train.columns
label_cols = 'Label'

X_train[label_cols] = y_train
X_test = pd.DataFrame(X_test)
X_test[label_cols] = y_test

# Normalize data
X_test[data_cols] = X_test[data_cols].div(X_test[data_cols].sum(axis=1), axis=0)
X_train[data_cols] = X_train[data_cols].div(X_train[data_cols].sum(axis=1), axis=0)
print(f"Test samples: {X_test.shape[0]}")
print(f"Train samples: {X_train.shape[0]}")

if colab_mode:
    display(X_train.iloc[:10])
else:
    print(tabulate(X_train.iloc[:10], headers='keys', tablefmt='psql'))

if not svm_mode:
    # create the model [ Embedding + Conv ]
    clf = Sequential()
    clf.add(Embedding(top_words, 32, input_length=max_words))
    clf.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))
    clf.add(MaxPooling1D(pool_size=2))
    clf.add(Flatten())
    clf.add(Dense(250, activation='relu'))
    clf.add(Dense(1, activation='sigmoid'))
    clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    print(clf.summary())
    clf.save_weights('original_w.h5')

else:
    # clf = svm.SVC(probability=True, kernel='poly')
    clf = KNN()

# Fit the model
start_time = datetime.now()
if not svm_mode:
    clf.fit(X_train[data_cols], X_train[label_cols], validation_data=(X_test[data_cols], X_test[label_cols]), epochs=5,
            batch_size=256, verbose=2)
    # Final evaluation of the model
    scores = clf.evaluate(X_test[data_cols], X_test[label_cols], verbose=0)
else:
    print("Fitting SVM")
    clf.fit(X_train[data_cols], X_train[label_cols])
    print("Predincting SVM")
    y_predicted = clf.predict(X_test[data_cols])
    accuracy = sklearn.metrics.accuracy_score(X_test[label_cols], y_predicted)
    scores = [0, accuracy]

print("Accuracy: %.2f%%" % (scores[1] * 100))
print(f"Duration: {datetime.now() - start_time}")

# Find an adverserial example to attack
attack_label = 1
attack_whithin_confidence_interval = [0.55, 0.60]
res = clf.predict_proba(X_test[data_cols])
res = pd.DataFrame(res, index=X_test.index)
res['Prediction'] = clf.predict(X_test[data_cols])
res[label_cols] = X_test[label_cols]
res = res[res[label_cols] == attack_label]

relevant_samples = (res['Prediction'] > attack_whithin_confidence_interval[0]) & (
        res['Prediction'] < attack_whithin_confidence_interval[1])
if relevant_samples.sum() > 0:
    res = res[(res['Prediction'] > attack_whithin_confidence_interval[0]) & (
            res['Prediction'] < attack_whithin_confidence_interval[1])]
else:
    mipoint = np.mean(attack_whithin_confidence_interval)
    res = res

adv_idx = res.sample(1).index[0]
adv = pd.DataFrame(columns=X_test.columns)
adv.loc[0] = X_test.loc[adv_idx]

if colab_mode:
    display(adv)
else:
    print(tabulate(adv, headers='keys', tablefmt='psql'))

print(f"Original prediction: {adv.loc[0,label_cols]}")
start_prob = clf.predict(adv[data_cols])[0, 0]
print(f"Classification: {np.round(start_prob)} prob: {start_prob:>.3f}")

# Attack params
df = X_train
budget = 2 * int(np.ceil(np.sqrt(df.shape[0])))
mutation_rate = 5 * 1.0 / budget
parents = 3

per_round_winner = pd.DataFrame(
    columns=['Gen', 'creature_idx', 'prob_of_origin',
             'prob_of_target', 'change'] + [
                's_{}'.format(tk) for tk in range(budget)])
result_summary = pd.DataFrame(columns=['Gen', 'Best score'])
results_memory = pd.DataFrame(columns=['parent_idx', 'prob_of_origin', 'prob_of_target'])


def run_creature(p):
    xdf = df.copy()
    xdf = xdf.drop(p, axis=0)
    clf.load_weights('original_w.h5')
    clf.fit(xdf[data_cols], xdf[label_cols], epochs=5, batch_size=9999999, verbose=0)
    # scores = clf.evaluate(X_test[data_cols], X_test[label_cols], verbose=0)
    # print("Accuracy: %.2f%%" % (scores[1]*100))
    # print(f"Original prediction: {adv.loc[0,label_cols]}")
    prob = clf.predict(adv[data_cols])[0, 0]
    # print(f"Classification: {np.round(prob)} prob: {prob:>.3f}")
    return prob


def mate(lp):
    # Pick genes
    genepool = set()
    for p in lp:
        genepool = genepool.union(p)
    child = np.random.choice(list(genepool), budget, replace=False)

    # Mutate
    items_to_mutate = sum(
        [np.random.choice([True, False], p=[mutation_rate, 1 - mutation_rate]) for _ in range(budget)])
    gene_options = df.index
    gene_options = np.setdiff1d(gene_options, child)

    items_to_remove = np.random.choice(list(child), items_to_mutate)
    child = np.setdiff1d(child, items_to_remove)

    items_to_add = np.random.choice(gene_options, items_to_mutate)
    child = set(child).union(items_to_add)

    return child


# Choose initial parents
adv_point = adv.loc[0, data_cols]
k_dist = lambda p: ((p - adv_point) ** 2).sum()

creatures_dict = dict()

tparent = df.copy(deep=True)
tparent = tparent[tparent[label_cols] == 1.0]
tparent = tparent[data_cols]
tparent['k_dist'] = tparent.apply(k_dist, axis=1)
tparent = tparent.sort_values(by=['k_dist'], ascending=True)
tparent = tparent.iloc[0:parents * budget]
tparent = tparent.drop(columns=['k_dist'])
tparent = tparent.sort_index()

tparents_idxs = tparent.index
gendf = pd.DataFrame(columns=['parent_idx', 'prob_of_origin', 'prob_of_target'], index=range(parents))
for cparent in range(parents):
    p = set(tparents_idxs[budget * cparent:budget * (cparent + 1)])
    hash_p = hash(str(p))
    prob_of_1 = run_creature(p)
    gendf.iloc[cparent] = [hash_p, prob_of_1, 1 - prob_of_1]
    creatures_dict[hash_p] = (p, prob_of_1)

if colab_mode:
    display(gendf)
else:
    print(tabulate(gendf, headers='keys', tablefmt='psql'))

generations = 200
offsprings = 50

num_of_creatures = offsprings + parents
xtnd_gendf = pd.DataFrame(columns=['parent_idx', 'prob_of_origin', 'prob_of_target'], index=range(num_of_creatures))
xtnd_gendf.iloc[0:parents] = gendf
res_across_gens = list()

for gen_idx in range(generations):
    hash_lp = xtnd_gendf['parent_idx'].iloc[0:parents].values
    lp = [creatures_dict[hash_tp][0] for hash_tp in hash_lp]

    # Run parents
    break_flag = False
    final_winner_idx = -1

    if colab_mode:
        loading_bar = tqdm.tqdm_notebook(enumerate(lp), desc=f' eval parents {gen_idx + 1} / {generations}')
    else:
        loading_bar = tqdm.tqdm(enumerate(lp), desc=f' eval parents {gen_idx + 1} / {generations}')

    for pidx, p in loading_bar:
        res = list()
        prob_of_0_1 = 1 - run_creature(p)
        prob_of_0_2 = 1 - run_creature(p)
        prob_of_0_3 = 1 - run_creature(p)
        res += [prob_of_0_1, prob_of_0_2, prob_of_0_3]
        prob_of_0 = np.mean(res)
        prob_of_1 = 1 - prob_of_0
        thrsh = 0.3
        if (prob_of_0_1 > thrsh) and (prob_of_0_2 > thrsh) and (prob_of_0_3 > thrsh):
            break_flag = True
            final_winner_idx = pidx
        if pidx == 0:
            res_across_gens += [prob_of_0]

        print(f"parent {pidx+1} score: {prob_of_0}. {res}")
        hash_p = hash(str(p))
        creatures_dict[hash_p] = (p, prob_of_1)
        xtnd_gendf.iloc[pidx] = [hash_p, prob_of_1, prob_of_0]

    plt.plot(res_across_gens)
    plt.show()
    plt.close('all')
    if break_flag:
        break

    # Run creatures
    if colab_mode:
        loading_bar = tqdm.tqdm_notebook(range(offsprings), desc=f' Gen {gen_idx + 1} / {generations}')
    else:
        loading_bar = tqdm.tqdm(range(offsprings), desc=f' Gen {gen_idx + 1} / {generations}')

    for cidx in loading_bar:
        creature_idx = cidx + parents
        cp = mate(lp)
        cp_hash = hash(str(cp))

        prob_of_1 = run_creature(cp)
        xtnd_gendf.iloc[creature_idx] = [cp_hash, prob_of_1, 1 - prob_of_1]
        creatures_dict[cp_hash] = (p, prob_of_1)
        # print(f"Hash: {cp_hash} Child {cidx} Score: {1 - prob_of_1}")

    xtnd_gendf = xtnd_gendf.sort_values(by=['prob_of_target'], ascending=False)
    gendf = xtnd_gendf
    print(f"Gen {gen_idx + 1}")

    if colab_mode:
        display(gendf)
    else:
        # print(tabulate(gendf, headers='keys', tablefmt='psql'))
        pass

# Analyze winner
winner = xtnd_gendf.iloc[final_winner_idx]
winner_hash = winner['parent_idx']
winner_p = creatures_dict[winner_hash][0]

xdf = df.copy()
xdf = xdf.drop(winner_p, axis=0)
clf.load_weights('original_w.h5')
clf.fit(xdf[data_cols], xdf[label_cols], epochs=10, batch_size=256, verbose=0)
scores = clf.evaluate(X_test[data_cols], X_test[label_cols], verbose=0)
prob = clf.predict(adv[data_cols])[0, 0]
print("Accuracy: %.2f%%" % (scores[1] * 100))
print(f"Original prediction: {adv.loc[0,label_cols]}")
print(f"Original prob: {start_prob}")
print(f"Current prediction: {prob}")
